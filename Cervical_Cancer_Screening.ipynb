{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cervical Cancer Screening - Kaggle Challenge\n",
    "\n",
    "Recently, Intel partnered with MobileODT to challenge Kagglers to develop an algorithm which accurately identifies a womanâ€™s cervix type based on images. Their motivation: doing so will prevent ineffectual treatments and allow healthcare providers to give proper referral for cases that require more advanced treatment.\n",
    "\n",
    "The following notebook is my solution for the presented task.\n",
    "\n",
    "In this competition, we had to develop algorithms to correctly classify cervix types based on cervical images. These different types of cervix in our data set are all considered normal (not cancerous), but since the transformation zones aren't always visible, some of the patients require further testing while some don't. This decision is very important for the healthcare provider and critical for the patient. Identifying the transformation zones is not an easy task for the healthcare providers, therefore, an algorithm-aided decision will significantly improve the quality and efficiency of cervical cancer screening for these patients. \n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The training dataset comprises of 1481 images belonging to 3 different categories, with the following distribution:\n",
    "    \n",
    "    1. Type 1 - 252 images\n",
    "    2. Type 2 - 780 images\n",
    "    3. Type 3 - 449 images\n",
    "    \n",
    "The competition was held in two stages where we were provided 2 test datasets for reporting our results. After stage 1, the output classes of stage 1 test images were released, so as to give kagglers a chance to improve and fine tune their models. The number of images provided for testing ast 2 stages are:\n",
    "    1. Stage 1 Test: 512 images\n",
    "    2. Stage 2 Test (Final): 4018 images\n",
    "    \n",
    "The final loss and accuracy were to be reported by tagging 4018 images.\n",
    "\n",
    "The dataset is available on Kaggle [here](https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Data preprocessing comprises of the following steps:\n",
    "    1. Resizing all images to same size (32 x 32 x 3)\n",
    "    2. Normalizing pixel values\n",
    "    3. Applying image deformations (Random Scaling + Rotations) for regularization\n",
    "    4. Storing data in a loadable numpy format\n",
    "    \n",
    "Below, you will find functions for implementing above mentioned tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter, ImageStat, Image, ImageDraw\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "def im_multi(path):\n",
    "    try:\n",
    "        im_stats_im_ = Image.open(path)\n",
    "        return [path, {'size': im_stats_im_.size}]\n",
    "    except:\n",
    "        print(path)\n",
    "        return [path, {'size': [0,0]}]\n",
    "\n",
    "def im_stats(im_stats_df):\n",
    "    im_stats_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(im_multi, im_stats_df['path'])\n",
    "    for i in range(len(ret)):\n",
    "        im_stats_d[ret[i][0]] = ret[i][1]\n",
    "    im_stats_df['size'] = im_stats_df['path'].map(lambda x: ' '.join(str(s) for s in im_stats_d[x]['size']))\n",
    "    return im_stats_df\n",
    "\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (32, 32), interpolation=cv2.INTER_LINEAR) #use cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n",
    "    return [path, resized]\n",
    "\n",
    "def normalize_image_features(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(get_im_cv2, paths)\n",
    "    for i in range(len(ret)):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "    ret = []\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    fdata = np.array(fdata, dtype=np.uint8)\n",
    "    fdata = fdata.transpose((0, 3, 1, 2))\n",
    "    fdata = fdata.astype('float32')\n",
    "    fdata = fdata / 255\n",
    "    return fdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model\n",
    "\n",
    "### 1. Load prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load('train.npy')\n",
    "train_target = np.load('train_target.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply image tranformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=0.3, zoom_range=0.3)\n",
    "datagen.fit(train_data)\n",
    "return datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a Convolutional Neural Network \n",
    "\n",
    "Using a CNN was a default choice given we have to build an image classifier.\n",
    "\n",
    "We shall be using: \n",
    "    1. Two 2D-Convolutional layers followed by Max Pooling layers\n",
    "    2. ReLU activations\n",
    "    3. Dropout between output of second convolutional block and input of fully connected layer\n",
    "    4. Two fully connected layers for classification with dropout\n",
    "    5. Hyperbolic Tan activation for FC-1 layer\n",
    "    6. Softmax activation for FC-2 layer (Obvious choice, given a multiclass classification problem)\n",
    "    7. Adamax optimizer - a variant of Adam based on the infinity norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), activation=\"relu\", input_shape=(3, 32, 32..., data_format=\"channels_first\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(strides=(2, 2), data_format=\"channels_first\", pool_size=(2, 2))`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(strides=(2, 2), data_format=\"channels_first\", pool_size=(2, 2))`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th', input_shape=(3, 32, 32))) #use input_shape=(3, 64, 64)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
    "model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model architecture looks as shown below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 4, 30, 30)         112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 15, 15)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 13, 13)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                3468      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 3,915\n",
      "Trainable params: 3,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_val_train,y_train,y_val_train = train_test_split(train_data,train_target,test_size=0.4, random_state=17)\n",
    "\n",
    "#fitting data\n",
    "model.fit_generator(datagen.flow(x_train,y_train, batch_size=15, shuffle=True), nb_epoch=200, samples_per_epoch=len(x_train), verbose=1, validation_data=(x_val_train, y_val_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = np.load('test1.npy')\n",
    "test_id = np.load('test_id1.npy')\n",
    "print(\"creating predictions\")\n",
    "predictions = model.predict_proba(test_data)\n",
    "print(\"predictions made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Writing output in Kaggle Submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns=['Type_1','Type_2','Type_3'])\n",
    "df['image_name'] = test_id\n",
    "df.to_csv('submission.csv', index=False)\n",
    "print(\"submission created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The simple convolutional model implemented in this notebook was able to generate a **score of 0.96407**.\n",
    "\n",
    "**This helped me achieve a rank of #110 on Kaggle leaderboard.**\n",
    "\n",
    "#### Future considerations:\n",
    "    1. I believe a higher score can be achieved by Transfer Learning. Fine tuning a pretrained model such as Inception-V3, VGG19, ResNet-50 can definitely boost the model accuracy.\n",
    "    \n",
    "    2. Many kagglers reported improved results by using R-CNN like approach i.e generating bounding boxes around regions of interest and generating probability predictions.\n",
    "    \n",
    "I would definitely like exploring these ideas in future implementations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
